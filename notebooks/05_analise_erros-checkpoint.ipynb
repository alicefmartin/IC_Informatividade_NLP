{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e6e6db-7741-4abc-8257-b18986d77088",
   "metadata": {},
   "source": [
    "# Análise qualitativa dos erros\n",
    "\n",
    "Este notebook tem como objetivo realizar uma análise qualitativa dos erros\n",
    "cometidos pelos modelos de classificação automática, comparando o baseline\n",
    "(TF-IDF + Regressão Logística) e o modelo baseado em embeddings contextualizados\n",
    "(BERTimbau).\n",
    "\n",
    "A análise busca identificar padrões linguísticos associados aos acertos e erros\n",
    "dos modelos, bem como discutir os limites da modelagem automática da\n",
    "informatividade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51b4f681-b269-4206-ad04-621b12fcecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfedb49-a0cc-4280-8190-a5b0db191fa8",
   "metadata": {},
   "source": [
    "## Carregamento do corpus\n",
    "\n",
    "Utilizamos o corpus final previamente construído, contendo as respostas, suas\n",
    "classificações finais e a origem da anotação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbe4c646-2bc4-47f1-84c6-6bf20fda9620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pergunta</th>\n",
       "      <th>resposta</th>\n",
       "      <th>tipo_resposta</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>n_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>O João e a Maria foram à festa?</td>\n",
       "      <td>A Maria foi.</td>\n",
       "      <td>subinformativa</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>O João e a Maria foram à festa?</td>\n",
       "      <td>Ninguém foi.</td>\n",
       "      <td>sobreinformativa</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>O Pedro e a Ana chegaram ao cinema?</td>\n",
       "      <td>A Ana chegou.</td>\n",
       "      <td>subinformativa</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>O Pedro e a Ana chegaram ao cinema?</td>\n",
       "      <td>Todos chegaram.</td>\n",
       "      <td>sobreinformativa</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>O Pedro e a Ana chegaram ao cinema?</td>\n",
       "      <td>Não chegaram.</td>\n",
       "      <td>completa</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                             pergunta         resposta     tipo_resposta  \\\n",
       "0   1      O João e a Maria foram à festa?     A Maria foi.    subinformativa   \n",
       "1   2      O João e a Maria foram à festa?     Ninguém foi.  sobreinformativa   \n",
       "2   4  O Pedro e a Ana chegaram ao cinema?    A Ana chegou.    subinformativa   \n",
       "3   5  O Pedro e a Ana chegaram ao cinema?  Todos chegaram.  sobreinformativa   \n",
       "4   6  O Pedro e a Ana chegaram ao cinema?    Não chegaram.          completa   \n",
       "\n",
       "   n_tokens  n_chars  \n",
       "0         3       12  \n",
       "1         2       12  \n",
       "2         3       13  \n",
       "3         2       15  \n",
       "4         2       13  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"corpus_modelagem.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7bce2-e278-463d-aa3c-27900f0873d7",
   "metadata": {},
   "source": [
    "## Definição do mapeamento de rótulos\n",
    "\n",
    "Os rótulos textuais são convertidos em identificadores numéricos para garantir\n",
    "consistência com os modelos treinados anteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2feba00-770d-43e1-8dba-eaa1d4beaf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'completa': 0, 'sobreinformativa': 1, 'subinformativa': 2},\n",
       " {0: 'completa', 1: 'sobreinformativa', 2: 'subinformativa'})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(df[\"tipo_resposta\"].unique())\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "label2id, id2label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c987e1-f616-406b-87da-c13e5704c2e6",
   "metadata": {},
   "source": [
    "## Seleção do subconjunto de modelagem\n",
    "\n",
    "Para garantir comparabilidade com os modelos treinados anteriormente,\n",
    "selecionamos apenas as instâncias pertencentes ao conjunto de teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1b2f3dc-9adb-4733-89aa-19b185abc2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resposta</th>\n",
       "      <th>classe_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Não leu.</td>\n",
       "      <td>completa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Todo mundo chegou.</td>\n",
       "      <td>sobreinformativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Não terminou.</td>\n",
       "      <td>completa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Sim, ele chegou.</td>\n",
       "      <td>completa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>A Maria concluiu.</td>\n",
       "      <td>subinformativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               resposta       classe_real\n",
       "62             Não leu.          completa\n",
       "173  Todo mundo chegou.  sobreinformativa\n",
       "209       Não terminou.          completa\n",
       "83     Sim, ele chegou.          completa\n",
       "76    A Maria concluiu.    subinformativa"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_model = df[df[\"tipo_resposta\"] != \"indefinida\"].copy()\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df_model,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_model[\"tipo_resposta\"]\n",
    ")\n",
    "\n",
    "df_test = test_df[[\"resposta\", \"tipo_resposta\"]].copy()\n",
    "df_test.rename(columns={\"tipo_resposta\": \"classe_real\"}, inplace=True)\n",
    "\n",
    "df_test.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382376c2-c603-465b-aacc-28c2eba4b241",
   "metadata": {},
   "source": [
    "## Predições do modelo baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "966b3889-a4f5-489a-b9a0-a2768cb11b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "baseline_model = joblib.load(\"baseline_tfidf_lr.joblib\")\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "452bd73c-6c9d-4948-97bf-1eff24a318ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"pred_baseline\"] = baseline_model.predict(\n",
    "    vectorizer.transform(df_test[\"resposta\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9294f2-c3b3-4e11-be0d-ac437114f176",
   "metadata": {},
   "source": [
    "## Predições do modelo com embeddings (BERTimbau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a6d07a2-5b50-44d4-880e-11b9067edcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d7a372a4f24a069dd0d3c5e41736aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alice\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "bert_test = Dataset.from_pandas(df_test[[\"resposta\"]])\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"resposta\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "bert_test = bert_test.map(tokenize, batched=True)\n",
    "bert_test.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\"]\n",
    ")\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_bert = Trainer(model=model_bert)\n",
    "\n",
    "bert_preds = trainer_bert.predict(bert_test)\n",
    "\n",
    "pred_bert = np.argmax(bert_preds.predictions, axis=1)\n",
    "\n",
    "df_test[\"pred_bert\"] = [id2label[i] for i in pred_bert]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569a491e-924f-4b91-a8ea-e5bc71426107",
   "metadata": {},
   "source": [
    "## Avaliação de acertos e erros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cb2d4e6-2621-4730-9200-d4ee49f012b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseline_acerta  bert_acerta\n",
       "True             False          29\n",
       "                 True           17\n",
       "False            True            1\n",
       "                 False           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"baseline_acerta\"] = (\n",
    "    df_test[\"pred_baseline\"] == df_test[\"classe_real\"]\n",
    ")\n",
    "\n",
    "df_test[\"bert_acerta\"] = (\n",
    "    df_test[\"pred_bert\"] == df_test[\"classe_real\"]\n",
    ")\n",
    "\n",
    "df_test[[\"baseline_acerta\", \"bert_acerta\"]].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e461269-dfc7-46fe-84a1-79b0ad43dd41",
   "metadata": {},
   "source": [
    "## Casos sensíveis a pistas lexicais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1668a187-f369-4443-9788-baf1bb2ab541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resposta</th>\n",
       "      <th>classe_real</th>\n",
       "      <th>pred_baseline</th>\n",
       "      <th>pred_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Não leu.</td>\n",
       "      <td>completa</td>\n",
       "      <td>completa</td>\n",
       "      <td>sobreinformativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Todo mundo chegou.</td>\n",
       "      <td>sobreinformativa</td>\n",
       "      <td>sobreinformativa</td>\n",
       "      <td>completa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Não terminou.</td>\n",
       "      <td>completa</td>\n",
       "      <td>completa</td>\n",
       "      <td>sobreinformativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Sim, ele chegou.</td>\n",
       "      <td>completa</td>\n",
       "      <td>completa</td>\n",
       "      <td>sobreinformativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>A Maria concluiu.</td>\n",
       "      <td>subinformativa</td>\n",
       "      <td>subinformativa</td>\n",
       "      <td>sobreinformativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               resposta       classe_real     pred_baseline         pred_bert\n",
       "62             Não leu.          completa          completa  sobreinformativa\n",
       "173  Todo mundo chegou.  sobreinformativa  sobreinformativa          completa\n",
       "209       Não terminou.          completa          completa  sobreinformativa\n",
       "83     Sim, ele chegou.          completa          completa  sobreinformativa\n",
       "76    A Maria concluiu.    subinformativa    subinformativa  sobreinformativa"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casos_lexicais = df_test[\n",
    "    (df_test[\"baseline_acerta\"]) &\n",
    "    (~df_test[\"bert_acerta\"])\n",
    "]\n",
    "\n",
    "casos_lexicais[[\"resposta\", \"classe_real\", \"pred_baseline\", \"pred_bert\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d579b27-8fba-4e01-bf35-0315c88ac454",
   "metadata": {},
   "source": [
    "## Discussão linguística\n",
    "\n",
    "Os exemplos acima indicam que pistas lexicais e estruturais, como extensão da\n",
    "resposta e uso de conectivos discursivos, são suficientes para a correta\n",
    "classificação em muitos casos, favorecendo o desempenho do modelo baseline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f009248c-bf9b-4c12-9f6b-ccddc6b9a86c",
   "metadata": {},
   "source": [
    "## Casos ambíguos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b79a0c3a-a5fc-4df0-a2a6-f0a6cafc3d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resposta</th>\n",
       "      <th>classe_real</th>\n",
       "      <th>pred_baseline</th>\n",
       "      <th>pred_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Comprou.</td>\n",
       "      <td>completa</td>\n",
       "      <td>sobreinformativa</td>\n",
       "      <td>sobreinformativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      resposta classe_real     pred_baseline         pred_bert\n",
       "122  Comprou.     completa  sobreinformativa  sobreinformativa"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casos_ambiguos = df_test[\n",
    "    (~df_test[\"baseline_acerta\"]) &\n",
    "    (~df_test[\"bert_acerta\"])\n",
    "]\n",
    "\n",
    "casos_ambiguos[[\"resposta\", \"classe_real\", \"pred_baseline\", \"pred_bert\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b65af-57cf-411a-bde1-41934398d3ac",
   "metadata": {},
   "source": [
    "## Discussão final \n",
    "\n",
    "Esses casos refletem limites da anotação atual e apontam para a necessidade de\n",
    "anotações inferenciais mais finas, como implicaturas conversacionais, para\n",
    "capturar adequadamente fenômenos pragmáticos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba709af-7478-4cd6-9d37-00e050cb4c1c",
   "metadata": {},
   "source": [
    "## Trabalhos futuros\n",
    "\n",
    "Pretende-se, em etapas futuras, incorporar anotações inferenciais ao corpus,\n",
    "avaliando se modelos baseados em embeddings apresentam vantagens quando\n",
    "fenômenos pragmáticos mais complexos são explicitamente representados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c3ff01-a370-415b-bba0-ee88d7183cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
