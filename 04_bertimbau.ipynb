{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f264f4-81a6-4776-aca3-78df46f6819a",
   "metadata": {},
   "source": [
    "# Classificação com embeddings: BERTimbau\n",
    "\n",
    "Este notebook implementa um modelo baseado em embeddings contextualizados\n",
    "(BERTimbau) para a tarefa de classificação automática de tipos de resposta.\n",
    "\n",
    "O objetivo é comparar o desempenho de um modelo neural pré-treinado com o\n",
    "baseline clássico baseado em TF-IDF e Regressão Logística.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6e661-3a57-45ae-bd2e-a9c862deea25",
   "metadata": {},
   "source": [
    "## Bibliotecas\n",
    "\n",
    "Utilizamos o modelo BERTimbau pré-treinado para o português brasileiro,\n",
    "disponibilizado pela comunidade HuggingFace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f410ab-2d51-441a-9da6-cb47deaab31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2811904-ac3d-49df-bcda-e318294deb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc56526a-aeb9-444b-bf01-8114d7811abf",
   "metadata": {},
   "source": [
    "## Carregamento do corpus\n",
    "\n",
    "Utilizamos o mesmo corpus de modelagem empregado no baseline, garantindo\n",
    "comparabilidade direta entre os modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6319cef9-bf0b-4d04-bd6f-ba7f30f52f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"corpus_modelagem.csv\")\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0e578-dcc1-45b9-a52b-b8610091875d",
   "metadata": {},
   "source": [
    "## Codificação das classes\n",
    "\n",
    "As categorias textuais são convertidas em rótulos numéricos para o treinamento\n",
    "do modelo neural.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f174445-c991-468b-ac2c-bdd6ffa54aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subinformativa': 0, 'sobreinformativa': 1, 'completa': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {label: i for i, label in enumerate(df[\"tipo_resposta\"].unique())}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "df[\"label\"] = df[\"tipo_resposta\"].map(label2id)\n",
    "\n",
    "label2id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9b652-7418-4f9f-bc9d-5c1a07f671f1",
   "metadata": {},
   "source": [
    "## Divisão treino/teste\n",
    "\n",
    "Utilizamos a mesma proporção treino/teste adotada no baseline (80/20).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2246ebde-0c69-4551-9fc8-eebf13efc432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((191, 7), (48, 7))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "train_df.shape, test_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfc054-a780-44fa-a491-069623e6d3e2",
   "metadata": {},
   "source": [
    "## Conversão para o formato Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b88bf40-b4ab-491e-ab1f-b6d8eb9cdbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(\n",
    "    train_df[[\"resposta\", \"label\"]]\n",
    ")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(\n",
    "    test_df[[\"resposta\", \"label\"]]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28174b7d-218e-41b3-b567-462aa8a90d2f",
   "metadata": {},
   "source": [
    "## Tokenização com BERTimbau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d8da26e-d25b-4128-8288-cc7935a91ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f985511833843b6a411ef8503afd567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alice\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\alice\\.cache\\huggingface\\hub\\models--neuralmind--bert-base-portuguese-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e8363b296e4b07bc88e00cef573991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d4d455885049abbe4ef0c8c816badf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84c114935394c6cb1c9303641165d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed780e3f13a4cbfbc566c90edaa1457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7f4837f46e4cf8a7e109e030f2c859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/191 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea0f8520ebc45b4aa06b273ee86455e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"neuralmind/bert-base-portuguese-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"resposta\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "train_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    ")\n",
    "\n",
    "test_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7315475-d891-4d0f-9802-6abe73471b37",
   "metadata": {},
   "source": [
    "## Definição do modelo\n",
    "\n",
    "Utilizamos fine-tuning completo do BERTimbau com uma camada de classificação\n",
    "linear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aff961ea-e762-421b-bffb-fb4cc68b290f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b14a8af1fc45a0ba2a4f9a6a968f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification LOAD REPORT from: neuralmind/bert-base-portuguese-cased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.predictions.decoder.weight             | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "classifier.weight                          | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e421a45-5673-42a4-94d8-12894730045a",
   "metadata": {},
   "source": [
    "## Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3be23d40-809f-4b8f-bb40-c2cdc5336c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0588d3-2cba-4edf-aa9b-1f9f9bcec625",
   "metadata": {},
   "source": [
    "## Configuração do treinamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec7bdb9b-4510-40d5-a8f2-aa128a25fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bertimbau\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c6410-967a-4e14-a1a8-9ade9140f270",
   "metadata": {},
   "source": [
    "## Treinamento do modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a620f1a-aef2-4a92-a81a-e4aac36707de",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70464ffa-6b62-4a2c-8ec1-8ae4f93e0be4",
   "metadata": {},
   "source": [
    "## Avaliação final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1d48405-23c7-4960-b39b-12c201fea9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alice\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1000031232833862,\n",
       " 'eval_model_preparation_time': 0.0067,\n",
       " 'eval_accuracy': 0.3958333333333333,\n",
       " 'eval_f1_macro': 0.19191919191919193,\n",
       " 'eval_runtime': 14.874,\n",
       " 'eval_samples_per_second': 3.227,\n",
       " 'eval_steps_per_second': 0.202}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dddbbe-ea56-4961-922f-9d0035e466f2",
   "metadata": {},
   "source": [
    "## Comparação com o baseline\n",
    "\n",
    "O modelo baseline baseado em TF-IDF e Regressão Logística apresentou desempenho\n",
    "superior (acurácia ≈ 96%) em comparação ao modelo baseado em embeddings\n",
    "contextualizados (BERTimbau), cujo desempenho foi consideravelmente inferior\n",
    "(acurácia ≈ 40%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f4cb4b6-d264-4e53-b522-b2e7ace0a540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Representação</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>F1-macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF + LR</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BERTimbau</td>\n",
       "      <td>Embeddings contextualizados</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>0.1919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Modelo                Representação  Acurácia  F1-macro\n",
       "0  TF-IDF + LR                       TF-IDF    0.9583    0.9500\n",
       "1    BERTimbau  Embeddings contextualizados    0.3958    0.1919"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "resultados = pd.DataFrame({\n",
    "    \"Modelo\": [\"TF-IDF + LR\", \"BERTimbau\"],\n",
    "    \"Representação\": [\"TF-IDF\", \"Embeddings contextualizados\"],\n",
    "    \"Acurácia\": [0.9583, 0.3958],\n",
    "    \"F1-macro\": [0.95, 0.1919]\n",
    "})\n",
    "\n",
    "resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2debba6a-5ff4-4ca6-86b1-bb26e88e8fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.to_csv(\"tabela_comparativa.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
